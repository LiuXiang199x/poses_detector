; Auto-generated. Do not edit!


(cl:in-package etts_msgs-msg)


;//! \htmlinclude UtteranceActionGoal.msg.html

(cl:defclass <UtteranceActionGoal> (roslisp-msg-protocol:ros-message)
  ((header
    :reader header
    :initarg :header
    :type std_msgs-msg:Header
    :initform (cl:make-instance 'std_msgs-msg:Header))
   (goal_id
    :reader goal_id
    :initarg :goal_id
    :type actionlib_msgs-msg:GoalID
    :initform (cl:make-instance 'actionlib_msgs-msg:GoalID))
   (goal
    :reader goal
    :initarg :goal
    :type etts_msgs-msg:UtteranceGoal
    :initform (cl:make-instance 'etts_msgs-msg:UtteranceGoal)))
)

(cl:defclass UtteranceActionGoal (<UtteranceActionGoal>)
  ())

(cl:defmethod cl:initialize-instance :after ((m <UtteranceActionGoal>) cl:&rest args)
  (cl:declare (cl:ignorable args))
  (cl:unless (cl:typep m 'UtteranceActionGoal)
    (roslisp-msg-protocol:msg-deprecation-warning "using old message class name etts_msgs-msg:<UtteranceActionGoal> is deprecated: use etts_msgs-msg:UtteranceActionGoal instead.")))

(cl:ensure-generic-function 'header-val :lambda-list '(m))
(cl:defmethod header-val ((m <UtteranceActionGoal>))
  (roslisp-msg-protocol:msg-deprecation-warning "Using old-style slot reader etts_msgs-msg:header-val is deprecated.  Use etts_msgs-msg:header instead.")
  (header m))

(cl:ensure-generic-function 'goal_id-val :lambda-list '(m))
(cl:defmethod goal_id-val ((m <UtteranceActionGoal>))
  (roslisp-msg-protocol:msg-deprecation-warning "Using old-style slot reader etts_msgs-msg:goal_id-val is deprecated.  Use etts_msgs-msg:goal_id instead.")
  (goal_id m))

(cl:ensure-generic-function 'goal-val :lambda-list '(m))
(cl:defmethod goal-val ((m <UtteranceActionGoal>))
  (roslisp-msg-protocol:msg-deprecation-warning "Using old-style slot reader etts_msgs-msg:goal-val is deprecated.  Use etts_msgs-msg:goal instead.")
  (goal m))
(cl:defmethod roslisp-msg-protocol:serialize ((msg <UtteranceActionGoal>) ostream)
  "Serializes a message object of type '<UtteranceActionGoal>"
  (roslisp-msg-protocol:serialize (cl:slot-value msg 'header) ostream)
  (roslisp-msg-protocol:serialize (cl:slot-value msg 'goal_id) ostream)
  (roslisp-msg-protocol:serialize (cl:slot-value msg 'goal) ostream)
)
(cl:defmethod roslisp-msg-protocol:deserialize ((msg <UtteranceActionGoal>) istream)
  "Deserializes a message object of type '<UtteranceActionGoal>"
  (roslisp-msg-protocol:deserialize (cl:slot-value msg 'header) istream)
  (roslisp-msg-protocol:deserialize (cl:slot-value msg 'goal_id) istream)
  (roslisp-msg-protocol:deserialize (cl:slot-value msg 'goal) istream)
  msg
)
(cl:defmethod roslisp-msg-protocol:ros-datatype ((msg (cl:eql '<UtteranceActionGoal>)))
  "Returns string type for a message object of type '<UtteranceActionGoal>"
  "etts_msgs/UtteranceActionGoal")
(cl:defmethod roslisp-msg-protocol:ros-datatype ((msg (cl:eql 'UtteranceActionGoal)))
  "Returns string type for a message object of type 'UtteranceActionGoal"
  "etts_msgs/UtteranceActionGoal")
(cl:defmethod roslisp-msg-protocol:md5sum ((type (cl:eql '<UtteranceActionGoal>)))
  "Returns md5sum for a message object of type '<UtteranceActionGoal>"
  "add8d67da9d5e62a59b0d0861fa3e729")
(cl:defmethod roslisp-msg-protocol:md5sum ((type (cl:eql 'UtteranceActionGoal)))
  "Returns md5sum for a message object of type 'UtteranceActionGoal"
  "add8d67da9d5e62a59b0d0861fa3e729")
(cl:defmethod roslisp-msg-protocol:message-definition ((type (cl:eql '<UtteranceActionGoal>)))
  "Returns full string definition for message of type '<UtteranceActionGoal>"
  (cl:format cl:nil "# ====== DO NOT MODIFY! AUTOGENERATED FROM AN ACTION DEFINITION ======~%~%Header header~%actionlib_msgs/GoalID goal_id~%UtteranceGoal goal~%~%================================================================================~%MSG: std_msgs/Header~%# Standard metadata for higher-level stamped data types.~%# This is generally used to communicate timestamped data ~%# in a particular coordinate frame.~%# ~%# sequence ID: consecutively increasing ID ~%uint32 seq~%#Two-integer timestamp that is expressed as:~%# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')~%# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')~%# time-handling sugar is provided by the client library~%time stamp~%#Frame this data is associated with~%# 0: no frame~%# 1: global frame~%string frame_id~%~%================================================================================~%MSG: actionlib_msgs/GoalID~%# The stamp should store the time at which this goal was requested.~%# It is used by an action server when it tries to preempt all~%# goals that were requested before a certain time~%time stamp~%~%# The id provides a way to associate feedback and~%# result message with specific goal requests. The id~%# specified must be unique.~%string id~%~%~%================================================================================~%MSG: etts_msgs/UtteranceGoal~%# ====== DO NOT MODIFY! AUTOGENERATED FROM AN ACTION DEFINITION ======~%#Goal definition: input parameters~%Utterance utterance~%~%================================================================================~%MSG: etts_msgs/Utterance~%####~%#### the messages sent to use the ETTS engine, via the topic \"etts\"~%####~%#### Apart from the info contained in this kind of message,~%#### these ROS parameters, written by the skill, can be useful for information:~%#### \"etts_language\" :  for example \"es\"~%#### \"etts_emotion\" :   for example \"happy\"~%#### \"etts_primitive\" : for example \"google\"~%#### \"etts_volume\" : integer in [VOLUME_MIN, VOLUME_MAX]~%#### \"etts_queue_size\" : for example \"2\"~%#### \"etts_speaking_now\" : true or false, set at the beginning and end of each sentence~%#### \"etts_current_sentence\": the sentence given to the low level primitive, for instance \"Hola\"~%####~%#### And the parameters written by the different APIs:~%#### \"etts_kidnapped\" : for example \"\" (not kidnapped) or \"node_name\"~%~%~%### useful for the stamp~%Header header~%~%### the real sentence to be said~%# A simple example: text=\"Hello world, how are you?\";~%#~%# -> if using FESTIVAL|GOOGLE|LOQUENDO|MICROSOFT|PICO|ESPEAK|NUANCE|IVONA|AT primitive:~%#    multi-languages support~%#    Example: text=\"es:hola|en:hi|en:Hello|fr:bonjour\";~%#    Multiple instances of a given language are supported,~%#    one of these will be chosen randomly.~%#    Example:  textMultiLanguage=\"en:Hello|en:Hi|fr:Salut\";~%#    if (target_language == LANGUAGE_ENGLISH), will return randomly \"Hello\" or \"Hi\"~%#    if (target_language == LANGUAGE_FRENCH), will return \"Salut\"~%#    (parsing is made in EttsSkill::process_utterance()~%#      -> Translator::_build_given_language_in_multilanguage_line() )~%#~%# -> if using FESTIVAL|GOOGLE|LOQUENDO|MICROSOFT|PICO|ESPEAK|NUANCE|IVONA|AT primitive:~%#    snippets support~%#    Example: text=\"Yes, \\\\NLG=OK let us do it\";~%#    replace the natural language snippets with their equivalent~%#    (parsing is made in EttsSkill::process_utterance()~%#      -> utterance_utils::replace_natural_langugage_tags() )~%#~%# -> if using FESTIVAL|GOOGLE|LOQUENDO|MICROSOFT|PICO|ESPEAK|NUANCE|IVONA|AT primitive:~%#    metadata tags support~%#    Emotion flags:~%#    Example: text=\"\\emotion=Happy I speak with a happy voice.\";~%#    Among \"HAPPY\", \"SAD\", \"TRANQUILITY\", \"NERVOUS\"~%#    (parsing is made in EttsSkill::process_utterance()~%#      -> EttsSkill::apply_metadata_tags() )~%#~%# -> if using LOQUENDO primitive: additional flags~%#    The Loquendo engine support a number of additional flags.~%#    Example: text=\"I had... \\\\pause=500 a complete relooking. \\\\item=Whistle_01\";~%#    These tags are stripped out of the sentence if another engine is used.~%#    (parsing is made in EttsSkill::process_utterance()~%#      -> utterance_utils::strip_metadata_tags() )~%#~%# -> if using NONVERBAL primitive: keys~%#    You must use one of the semantic keys of non_verbal.h:~%#    \"SINGING\"|\"CONFIRMATION\"|\"THINKING\"|\"WARNING\"|\"DIALOG\"|\"HELLO\"|\"ERROR\"|\"AMAZING\"~%#    Example: text=\"SINGING\";~%#~%# -> if using  MUSIC_SCORE primitive, use a music score (cf etts_music_score.h)~%#    Example:  text=\"BPM=85,A6,{},Ab2,C5,1/4-C3\";~%#    You can also use a filepath, it must end with \".score\".~%#    For example text=\"/tmp/mymusic.score\".~%#    This file must contain a valid music score, for instance \"C4,D4,E4,D4,C4\"~%#~%# Note that if using NONVERBAL and MUSIC_SCORE,~%#   multi-language, metadata, snippets are not used.~%#   However, the language and the emotion fields of the message are applied as usual.~%string text~%~%### language domain~%# \"en\" for english, \"es\" for spanish, etc.~%# empty (\"\") for keeping the same language~%string language~%~%# re-use the same primitive that was used in the last sentence~%int16 PRIM_LAST_USED = 0~%# open source, homebrew - does not emit any sound (mute)~%int16 PRIM_NOVOICE = 1~%# open source - based on the Festival project, by the University of Edinburgh~%# http://www.cstr.ed.ac.uk/projects/festival/~%int16 PRIM_FESTIVAL = 2~%# prorietary, webservice - Google TTS webservice, most notably used in Google Translate~%# https://en.wikipedia.org/wiki/Google_Text-to-Speech~%int16 PRIM_GOOGLE = 3~%# prorietary - based on the Loquendo binaries~%# http://www.nuance.com/for-business/customer-service-solutions/loquendo-small-business-bundle/index.htm~%int16 PRIM_LOQUENDO = 4~%# prorietary, webservice - the speech synthesizer developed by Microsoft for its OS~%# https://en.wikipedia.org/wiki/Microsoft_text-to-speech_voices~%int16 PRIM_MICROSOFT = 5~%# open source, homebrew - beep and other sounds~%int16 PRIM_NONVERBAL = 6~%# open source, homebrew - generate music sounds based the music score, written in notes~%int16 PRIM_MUSIC_SCORE = 7~%# open source - based on pico2wave, a small footprint TTS released by SVOX~%# https://en.wikipedia.org/wiki/SVOX~%int16 PRIM_PICO = 8~%# open source - based on the espeak utility, a multi-lingual software speech synthesizer~%# http://espeak.sourceforge.net/~%int16 PRIM_ESPEAK = 9~%# prorietary, webservice - uses the mobile Nuance Mobility webservice~%# http://www.nuance.com/for-business/customer-service-solutions/loquendo-small-business-bundle/index.htm~%int16 PRIM_NUANCE = 10~%# prorietary, webservice - uses the IVONA TTS webservice for developpers~%# http://developer.ivona.com/en/speechcloud/index.html~%int16 PRIM_IVONA = 11~%# prorietary, webservice - AT&T TTS webservice~%# http://www2.research.att.com/~~ttsweb/tts/~%int16 PRIM_AT = 12~%# prorietary~%# https://www.readspeaker.com~%int16 PRIM_READSPEAKER = 13~%~%# the wanted low-level voice engine: one of the previous PRIM_*~%# leave empty (PRIM_LAST_USED) for keeping the same primitive~%int16 primitive~%~%~%#The identifier of the utterance in oder to know when the utterance begins and ends.~%#This identifier  could be the miliseconds of the system, in this way it's unequivocal~%#To get the identifier you can use this boost funtion:  boost::posix_time::second_clock::local_time();~%int64 utteranceIdentifier~%~%~%~%int16 EMOTION_LAST_USED = 0~%int16 EMOTION_HAPPY = 1~%int16 EMOTION_SAD = 2~%int16 EMOTION_NEUTRAL = 3~%int16 EMOTION_ANXIOUS = 4~%int16 EMOTION_RELAXED = 5~%int16 EMOTION_ANGRY = 6~%int16 EMOTION_BORED = 7~%int16 EMOTION_SURPRISED = 8~%~%### the wanted emotion, if supported by the primitive~%# use one of the previous EMOTION_*~%# leave empty (EMOTION_LAST_USED) for keeping the same emotion~%int16 emotion~%~%~%~%### the parameters that configure the voice (ALPHA VERSION)~%int16 paralinguistic~%int16 pitch~%float32 prosody_rate~%~%~%~%int16 VOLUME_LAST_USED = 0~%int16 VOLUME_MIN = 1~%int16 VOLUME_MAX = 100~%### the desired volume output, if supported by the primitive~%# volume must be between VOLUME_MIN and VOLUME_MAX~%# leave empty (VOLUME_LAST_USED) for no change~%int16 volume~%~%int16 QUEUE_SENTENCE = 0~%int16 SHUTUP_IMMEDIATLY_AND_SAY_SENTENCE = 1~%int16 SHUTUP_AND_SAY_SENTENCE = 2~%int16 PAUSE = 3~%int16 RESUME = 4~%int16 SPEAK_ONLY_IF_ROBOT_QUIET = 5~%### by default, queue the sentence and say it when the previous ones have been said.~%#  Use one of the previous orders to change this behaviour.~%#  Note that if using the special instructions PAUSE and RESUME,~%#  all the other fields of the message (including text) are discarded.~%int16 priority~%~%~%"))
(cl:defmethod roslisp-msg-protocol:message-definition ((type (cl:eql 'UtteranceActionGoal)))
  "Returns full string definition for message of type 'UtteranceActionGoal"
  (cl:format cl:nil "# ====== DO NOT MODIFY! AUTOGENERATED FROM AN ACTION DEFINITION ======~%~%Header header~%actionlib_msgs/GoalID goal_id~%UtteranceGoal goal~%~%================================================================================~%MSG: std_msgs/Header~%# Standard metadata for higher-level stamped data types.~%# This is generally used to communicate timestamped data ~%# in a particular coordinate frame.~%# ~%# sequence ID: consecutively increasing ID ~%uint32 seq~%#Two-integer timestamp that is expressed as:~%# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')~%# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')~%# time-handling sugar is provided by the client library~%time stamp~%#Frame this data is associated with~%# 0: no frame~%# 1: global frame~%string frame_id~%~%================================================================================~%MSG: actionlib_msgs/GoalID~%# The stamp should store the time at which this goal was requested.~%# It is used by an action server when it tries to preempt all~%# goals that were requested before a certain time~%time stamp~%~%# The id provides a way to associate feedback and~%# result message with specific goal requests. The id~%# specified must be unique.~%string id~%~%~%================================================================================~%MSG: etts_msgs/UtteranceGoal~%# ====== DO NOT MODIFY! AUTOGENERATED FROM AN ACTION DEFINITION ======~%#Goal definition: input parameters~%Utterance utterance~%~%================================================================================~%MSG: etts_msgs/Utterance~%####~%#### the messages sent to use the ETTS engine, via the topic \"etts\"~%####~%#### Apart from the info contained in this kind of message,~%#### these ROS parameters, written by the skill, can be useful for information:~%#### \"etts_language\" :  for example \"es\"~%#### \"etts_emotion\" :   for example \"happy\"~%#### \"etts_primitive\" : for example \"google\"~%#### \"etts_volume\" : integer in [VOLUME_MIN, VOLUME_MAX]~%#### \"etts_queue_size\" : for example \"2\"~%#### \"etts_speaking_now\" : true or false, set at the beginning and end of each sentence~%#### \"etts_current_sentence\": the sentence given to the low level primitive, for instance \"Hola\"~%####~%#### And the parameters written by the different APIs:~%#### \"etts_kidnapped\" : for example \"\" (not kidnapped) or \"node_name\"~%~%~%### useful for the stamp~%Header header~%~%### the real sentence to be said~%# A simple example: text=\"Hello world, how are you?\";~%#~%# -> if using FESTIVAL|GOOGLE|LOQUENDO|MICROSOFT|PICO|ESPEAK|NUANCE|IVONA|AT primitive:~%#    multi-languages support~%#    Example: text=\"es:hola|en:hi|en:Hello|fr:bonjour\";~%#    Multiple instances of a given language are supported,~%#    one of these will be chosen randomly.~%#    Example:  textMultiLanguage=\"en:Hello|en:Hi|fr:Salut\";~%#    if (target_language == LANGUAGE_ENGLISH), will return randomly \"Hello\" or \"Hi\"~%#    if (target_language == LANGUAGE_FRENCH), will return \"Salut\"~%#    (parsing is made in EttsSkill::process_utterance()~%#      -> Translator::_build_given_language_in_multilanguage_line() )~%#~%# -> if using FESTIVAL|GOOGLE|LOQUENDO|MICROSOFT|PICO|ESPEAK|NUANCE|IVONA|AT primitive:~%#    snippets support~%#    Example: text=\"Yes, \\\\NLG=OK let us do it\";~%#    replace the natural language snippets with their equivalent~%#    (parsing is made in EttsSkill::process_utterance()~%#      -> utterance_utils::replace_natural_langugage_tags() )~%#~%# -> if using FESTIVAL|GOOGLE|LOQUENDO|MICROSOFT|PICO|ESPEAK|NUANCE|IVONA|AT primitive:~%#    metadata tags support~%#    Emotion flags:~%#    Example: text=\"\\emotion=Happy I speak with a happy voice.\";~%#    Among \"HAPPY\", \"SAD\", \"TRANQUILITY\", \"NERVOUS\"~%#    (parsing is made in EttsSkill::process_utterance()~%#      -> EttsSkill::apply_metadata_tags() )~%#~%# -> if using LOQUENDO primitive: additional flags~%#    The Loquendo engine support a number of additional flags.~%#    Example: text=\"I had... \\\\pause=500 a complete relooking. \\\\item=Whistle_01\";~%#    These tags are stripped out of the sentence if another engine is used.~%#    (parsing is made in EttsSkill::process_utterance()~%#      -> utterance_utils::strip_metadata_tags() )~%#~%# -> if using NONVERBAL primitive: keys~%#    You must use one of the semantic keys of non_verbal.h:~%#    \"SINGING\"|\"CONFIRMATION\"|\"THINKING\"|\"WARNING\"|\"DIALOG\"|\"HELLO\"|\"ERROR\"|\"AMAZING\"~%#    Example: text=\"SINGING\";~%#~%# -> if using  MUSIC_SCORE primitive, use a music score (cf etts_music_score.h)~%#    Example:  text=\"BPM=85,A6,{},Ab2,C5,1/4-C3\";~%#    You can also use a filepath, it must end with \".score\".~%#    For example text=\"/tmp/mymusic.score\".~%#    This file must contain a valid music score, for instance \"C4,D4,E4,D4,C4\"~%#~%# Note that if using NONVERBAL and MUSIC_SCORE,~%#   multi-language, metadata, snippets are not used.~%#   However, the language and the emotion fields of the message are applied as usual.~%string text~%~%### language domain~%# \"en\" for english, \"es\" for spanish, etc.~%# empty (\"\") for keeping the same language~%string language~%~%# re-use the same primitive that was used in the last sentence~%int16 PRIM_LAST_USED = 0~%# open source, homebrew - does not emit any sound (mute)~%int16 PRIM_NOVOICE = 1~%# open source - based on the Festival project, by the University of Edinburgh~%# http://www.cstr.ed.ac.uk/projects/festival/~%int16 PRIM_FESTIVAL = 2~%# prorietary, webservice - Google TTS webservice, most notably used in Google Translate~%# https://en.wikipedia.org/wiki/Google_Text-to-Speech~%int16 PRIM_GOOGLE = 3~%# prorietary - based on the Loquendo binaries~%# http://www.nuance.com/for-business/customer-service-solutions/loquendo-small-business-bundle/index.htm~%int16 PRIM_LOQUENDO = 4~%# prorietary, webservice - the speech synthesizer developed by Microsoft for its OS~%# https://en.wikipedia.org/wiki/Microsoft_text-to-speech_voices~%int16 PRIM_MICROSOFT = 5~%# open source, homebrew - beep and other sounds~%int16 PRIM_NONVERBAL = 6~%# open source, homebrew - generate music sounds based the music score, written in notes~%int16 PRIM_MUSIC_SCORE = 7~%# open source - based on pico2wave, a small footprint TTS released by SVOX~%# https://en.wikipedia.org/wiki/SVOX~%int16 PRIM_PICO = 8~%# open source - based on the espeak utility, a multi-lingual software speech synthesizer~%# http://espeak.sourceforge.net/~%int16 PRIM_ESPEAK = 9~%# prorietary, webservice - uses the mobile Nuance Mobility webservice~%# http://www.nuance.com/for-business/customer-service-solutions/loquendo-small-business-bundle/index.htm~%int16 PRIM_NUANCE = 10~%# prorietary, webservice - uses the IVONA TTS webservice for developpers~%# http://developer.ivona.com/en/speechcloud/index.html~%int16 PRIM_IVONA = 11~%# prorietary, webservice - AT&T TTS webservice~%# http://www2.research.att.com/~~ttsweb/tts/~%int16 PRIM_AT = 12~%# prorietary~%# https://www.readspeaker.com~%int16 PRIM_READSPEAKER = 13~%~%# the wanted low-level voice engine: one of the previous PRIM_*~%# leave empty (PRIM_LAST_USED) for keeping the same primitive~%int16 primitive~%~%~%#The identifier of the utterance in oder to know when the utterance begins and ends.~%#This identifier  could be the miliseconds of the system, in this way it's unequivocal~%#To get the identifier you can use this boost funtion:  boost::posix_time::second_clock::local_time();~%int64 utteranceIdentifier~%~%~%~%int16 EMOTION_LAST_USED = 0~%int16 EMOTION_HAPPY = 1~%int16 EMOTION_SAD = 2~%int16 EMOTION_NEUTRAL = 3~%int16 EMOTION_ANXIOUS = 4~%int16 EMOTION_RELAXED = 5~%int16 EMOTION_ANGRY = 6~%int16 EMOTION_BORED = 7~%int16 EMOTION_SURPRISED = 8~%~%### the wanted emotion, if supported by the primitive~%# use one of the previous EMOTION_*~%# leave empty (EMOTION_LAST_USED) for keeping the same emotion~%int16 emotion~%~%~%~%### the parameters that configure the voice (ALPHA VERSION)~%int16 paralinguistic~%int16 pitch~%float32 prosody_rate~%~%~%~%int16 VOLUME_LAST_USED = 0~%int16 VOLUME_MIN = 1~%int16 VOLUME_MAX = 100~%### the desired volume output, if supported by the primitive~%# volume must be between VOLUME_MIN and VOLUME_MAX~%# leave empty (VOLUME_LAST_USED) for no change~%int16 volume~%~%int16 QUEUE_SENTENCE = 0~%int16 SHUTUP_IMMEDIATLY_AND_SAY_SENTENCE = 1~%int16 SHUTUP_AND_SAY_SENTENCE = 2~%int16 PAUSE = 3~%int16 RESUME = 4~%int16 SPEAK_ONLY_IF_ROBOT_QUIET = 5~%### by default, queue the sentence and say it when the previous ones have been said.~%#  Use one of the previous orders to change this behaviour.~%#  Note that if using the special instructions PAUSE and RESUME,~%#  all the other fields of the message (including text) are discarded.~%int16 priority~%~%~%"))
(cl:defmethod roslisp-msg-protocol:serialization-length ((msg <UtteranceActionGoal>))
  (cl:+ 0
     (roslisp-msg-protocol:serialization-length (cl:slot-value msg 'header))
     (roslisp-msg-protocol:serialization-length (cl:slot-value msg 'goal_id))
     (roslisp-msg-protocol:serialization-length (cl:slot-value msg 'goal))
))
(cl:defmethod roslisp-msg-protocol:ros-message-to-list ((msg <UtteranceActionGoal>))
  "Converts a ROS message object to a list"
  (cl:list 'UtteranceActionGoal
    (cl:cons ':header (header msg))
    (cl:cons ':goal_id (goal_id msg))
    (cl:cons ':goal (goal msg))
))
