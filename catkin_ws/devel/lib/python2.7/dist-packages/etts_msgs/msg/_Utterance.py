# This Python file uses the following encoding: utf-8
"""autogenerated by genpy from etts_msgs/Utterance.msg. Do not edit."""
import codecs
import sys
python3 = True if sys.hexversion > 0x03000000 else False
import genpy
import struct

import std_msgs.msg

class Utterance(genpy.Message):
  _md5sum = "ed088da8fc9f0bef0a7656c5687abdcc"
  _type = "etts_msgs/Utterance"
  _has_header = True  # flag to mark the presence of a Header object
  _full_text = """####
#### the messages sent to use the ETTS engine, via the topic "etts"
####
#### Apart from the info contained in this kind of message,
#### these ROS parameters, written by the skill, can be useful for information:
#### "etts_language" :  for example "es"
#### "etts_emotion" :   for example "happy"
#### "etts_primitive" : for example "google"
#### "etts_volume" : integer in [VOLUME_MIN, VOLUME_MAX]
#### "etts_queue_size" : for example "2"
#### "etts_speaking_now" : true or false, set at the beginning and end of each sentence
#### "etts_current_sentence": the sentence given to the low level primitive, for instance "Hola"
####
#### And the parameters written by the different APIs:
#### "etts_kidnapped" : for example "" (not kidnapped) or "node_name"


### useful for the stamp
Header header

### the real sentence to be said
# A simple example: text="Hello world, how are you?";
#
# -> if using FESTIVAL|GOOGLE|LOQUENDO|MICROSOFT|PICO|ESPEAK|NUANCE|IVONA|AT primitive:
#    multi-languages support
#    Example: text="es:hola|en:hi|en:Hello|fr:bonjour";
#    Multiple instances of a given language are supported,
#    one of these will be chosen randomly.
#    Example:  textMultiLanguage="en:Hello|en:Hi|fr:Salut";
#    if (target_language == LANGUAGE_ENGLISH), will return randomly "Hello" or "Hi"
#    if (target_language == LANGUAGE_FRENCH), will return "Salut"
#    (parsing is made in EttsSkill::process_utterance()
#      -> Translator::_build_given_language_in_multilanguage_line() )
#
# -> if using FESTIVAL|GOOGLE|LOQUENDO|MICROSOFT|PICO|ESPEAK|NUANCE|IVONA|AT primitive:
#    snippets support
#    Example: text="Yes, \\NLG=OK let us do it";
#    replace the natural language snippets with their equivalent
#    (parsing is made in EttsSkill::process_utterance()
#      -> utterance_utils::replace_natural_langugage_tags() )
#
# -> if using FESTIVAL|GOOGLE|LOQUENDO|MICROSOFT|PICO|ESPEAK|NUANCE|IVONA|AT primitive:
#    metadata tags support
#    Emotion flags:
#    Example: text="\emotion=Happy I speak with a happy voice.";
#    Among "HAPPY", "SAD", "TRANQUILITY", "NERVOUS"
#    (parsing is made in EttsSkill::process_utterance()
#      -> EttsSkill::apply_metadata_tags() )
#
# -> if using LOQUENDO primitive: additional flags
#    The Loquendo engine support a number of additional flags.
#    Example: text="I had... \\pause=500 a complete relooking. \\item=Whistle_01";
#    These tags are stripped out of the sentence if another engine is used.
#    (parsing is made in EttsSkill::process_utterance()
#      -> utterance_utils::strip_metadata_tags() )
#
# -> if using NONVERBAL primitive: keys
#    You must use one of the semantic keys of non_verbal.h:
#    "SINGING"|"CONFIRMATION"|"THINKING"|"WARNING"|"DIALOG"|"HELLO"|"ERROR"|"AMAZING"
#    Example: text="SINGING";
#
# -> if using  MUSIC_SCORE primitive, use a music score (cf etts_music_score.h)
#    Example:  text="BPM=85,A6,{},Ab2,C5,1/4-C3";
#    You can also use a filepath, it must end with ".score".
#    For example text="/tmp/mymusic.score".
#    This file must contain a valid music score, for instance "C4,D4,E4,D4,C4"
#
# Note that if using NONVERBAL and MUSIC_SCORE,
#   multi-language, metadata, snippets are not used.
#   However, the language and the emotion fields of the message are applied as usual.
string text

### language domain
# "en" for english, "es" for spanish, etc.
# empty ("") for keeping the same language
string language

# re-use the same primitive that was used in the last sentence
int16 PRIM_LAST_USED = 0
# open source, homebrew - does not emit any sound (mute)
int16 PRIM_NOVOICE = 1
# open source - based on the Festival project, by the University of Edinburgh
# http://www.cstr.ed.ac.uk/projects/festival/
int16 PRIM_FESTIVAL = 2
# prorietary, webservice - Google TTS webservice, most notably used in Google Translate
# https://en.wikipedia.org/wiki/Google_Text-to-Speech
int16 PRIM_GOOGLE = 3
# prorietary - based on the Loquendo binaries
# http://www.nuance.com/for-business/customer-service-solutions/loquendo-small-business-bundle/index.htm
int16 PRIM_LOQUENDO = 4
# prorietary, webservice - the speech synthesizer developed by Microsoft for its OS
# https://en.wikipedia.org/wiki/Microsoft_text-to-speech_voices
int16 PRIM_MICROSOFT = 5
# open source, homebrew - beep and other sounds
int16 PRIM_NONVERBAL = 6
# open source, homebrew - generate music sounds based the music score, written in notes
int16 PRIM_MUSIC_SCORE = 7
# open source - based on pico2wave, a small footprint TTS released by SVOX
# https://en.wikipedia.org/wiki/SVOX
int16 PRIM_PICO = 8
# open source - based on the espeak utility, a multi-lingual software speech synthesizer
# http://espeak.sourceforge.net/
int16 PRIM_ESPEAK = 9
# prorietary, webservice - uses the mobile Nuance Mobility webservice
# http://www.nuance.com/for-business/customer-service-solutions/loquendo-small-business-bundle/index.htm
int16 PRIM_NUANCE = 10
# prorietary, webservice - uses the IVONA TTS webservice for developpers
# http://developer.ivona.com/en/speechcloud/index.html
int16 PRIM_IVONA = 11
# prorietary, webservice - AT&T TTS webservice
# http://www2.research.att.com/~ttsweb/tts/
int16 PRIM_AT = 12
# prorietary
# https://www.readspeaker.com
int16 PRIM_READSPEAKER = 13

# the wanted low-level voice engine: one of the previous PRIM_*
# leave empty (PRIM_LAST_USED) for keeping the same primitive
int16 primitive


#The identifier of the utterance in oder to know when the utterance begins and ends.
#This identifier  could be the miliseconds of the system, in this way it's unequivocal
#To get the identifier you can use this boost funtion:  boost::posix_time::second_clock::local_time();
int64 utteranceIdentifier



int16 EMOTION_LAST_USED = 0
int16 EMOTION_HAPPY = 1
int16 EMOTION_SAD = 2
int16 EMOTION_NEUTRAL = 3
int16 EMOTION_ANXIOUS = 4
int16 EMOTION_RELAXED = 5
int16 EMOTION_ANGRY = 6
int16 EMOTION_BORED = 7
int16 EMOTION_SURPRISED = 8

### the wanted emotion, if supported by the primitive
# use one of the previous EMOTION_*
# leave empty (EMOTION_LAST_USED) for keeping the same emotion
int16 emotion



### the parameters that configure the voice (ALPHA VERSION)
int16 paralinguistic
int16 pitch
float32 prosody_rate



int16 VOLUME_LAST_USED = 0
int16 VOLUME_MIN = 1
int16 VOLUME_MAX = 100
### the desired volume output, if supported by the primitive
# volume must be between VOLUME_MIN and VOLUME_MAX
# leave empty (VOLUME_LAST_USED) for no change
int16 volume

int16 QUEUE_SENTENCE = 0
int16 SHUTUP_IMMEDIATLY_AND_SAY_SENTENCE = 1
int16 SHUTUP_AND_SAY_SENTENCE = 2
int16 PAUSE = 3
int16 RESUME = 4
int16 SPEAK_ONLY_IF_ROBOT_QUIET = 5
### by default, queue the sentence and say it when the previous ones have been said.
#  Use one of the previous orders to change this behaviour.
#  Note that if using the special instructions PAUSE and RESUME,
#  all the other fields of the message (including text) are discarded.
int16 priority

================================================================================
MSG: std_msgs/Header
# Standard metadata for higher-level stamped data types.
# This is generally used to communicate timestamped data 
# in a particular coordinate frame.
# 
# sequence ID: consecutively increasing ID 
uint32 seq
#Two-integer timestamp that is expressed as:
# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')
# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')
# time-handling sugar is provided by the client library
time stamp
#Frame this data is associated with
# 0: no frame
# 1: global frame
string frame_id
"""
  # Pseudo-constants
  PRIM_LAST_USED = 0
  PRIM_NOVOICE = 1
  PRIM_FESTIVAL = 2
  PRIM_GOOGLE = 3
  PRIM_LOQUENDO = 4
  PRIM_MICROSOFT = 5
  PRIM_NONVERBAL = 6
  PRIM_MUSIC_SCORE = 7
  PRIM_PICO = 8
  PRIM_ESPEAK = 9
  PRIM_NUANCE = 10
  PRIM_IVONA = 11
  PRIM_AT = 12
  PRIM_READSPEAKER = 13
  EMOTION_LAST_USED = 0
  EMOTION_HAPPY = 1
  EMOTION_SAD = 2
  EMOTION_NEUTRAL = 3
  EMOTION_ANXIOUS = 4
  EMOTION_RELAXED = 5
  EMOTION_ANGRY = 6
  EMOTION_BORED = 7
  EMOTION_SURPRISED = 8
  VOLUME_LAST_USED = 0
  VOLUME_MIN = 1
  VOLUME_MAX = 100
  QUEUE_SENTENCE = 0
  SHUTUP_IMMEDIATLY_AND_SAY_SENTENCE = 1
  SHUTUP_AND_SAY_SENTENCE = 2
  PAUSE = 3
  RESUME = 4
  SPEAK_ONLY_IF_ROBOT_QUIET = 5

  __slots__ = ['header','text','language','primitive','utteranceIdentifier','emotion','paralinguistic','pitch','prosody_rate','volume','priority']
  _slot_types = ['std_msgs/Header','string','string','int16','int64','int16','int16','int16','float32','int16','int16']

  def __init__(self, *args, **kwds):
    """
    Constructor. Any message fields that are implicitly/explicitly
    set to None will be assigned a default value. The recommend
    use is keyword arguments as this is more robust to future message
    changes.  You cannot mix in-order arguments and keyword arguments.

    The available fields are:
       header,text,language,primitive,utteranceIdentifier,emotion,paralinguistic,pitch,prosody_rate,volume,priority

    :param args: complete set of field values, in .msg order
    :param kwds: use keyword arguments corresponding to message field names
    to set specific fields.
    """
    if args or kwds:
      super(Utterance, self).__init__(*args, **kwds)
      # message fields cannot be None, assign default values for those that are
      if self.header is None:
        self.header = std_msgs.msg.Header()
      if self.text is None:
        self.text = ''
      if self.language is None:
        self.language = ''
      if self.primitive is None:
        self.primitive = 0
      if self.utteranceIdentifier is None:
        self.utteranceIdentifier = 0
      if self.emotion is None:
        self.emotion = 0
      if self.paralinguistic is None:
        self.paralinguistic = 0
      if self.pitch is None:
        self.pitch = 0
      if self.prosody_rate is None:
        self.prosody_rate = 0.
      if self.volume is None:
        self.volume = 0
      if self.priority is None:
        self.priority = 0
    else:
      self.header = std_msgs.msg.Header()
      self.text = ''
      self.language = ''
      self.primitive = 0
      self.utteranceIdentifier = 0
      self.emotion = 0
      self.paralinguistic = 0
      self.pitch = 0
      self.prosody_rate = 0.
      self.volume = 0
      self.priority = 0

  def _get_types(self):
    """
    internal API method
    """
    return self._slot_types

  def serialize(self, buff):
    """
    serialize message into buffer
    :param buff: buffer, ``StringIO``
    """
    try:
      _x = self
      buff.write(_get_struct_3I().pack(_x.header.seq, _x.header.stamp.secs, _x.header.stamp.nsecs))
      _x = self.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self.text
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self.language
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_hq3hf2h().pack(_x.primitive, _x.utteranceIdentifier, _x.emotion, _x.paralinguistic, _x.pitch, _x.prosody_rate, _x.volume, _x.priority))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize(self, str):
    """
    unpack serialized message in str into this message instance
    :param str: byte array of serialized message, ``str``
    """
    codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      if self.header is None:
        self.header = std_msgs.msg.Header()
      end = 0
      _x = self
      start = end
      end += 12
      (_x.header.seq, _x.header.stamp.secs, _x.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.header.frame_id = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.text = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.text = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.language = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.language = str[start:end]
      _x = self
      start = end
      end += 24
      (_x.primitive, _x.utteranceIdentifier, _x.emotion, _x.paralinguistic, _x.pitch, _x.prosody_rate, _x.volume, _x.priority,) = _get_struct_hq3hf2h().unpack(str[start:end])
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill


  def serialize_numpy(self, buff, numpy):
    """
    serialize message with numpy array types into buffer
    :param buff: buffer, ``StringIO``
    :param numpy: numpy python module
    """
    try:
      _x = self
      buff.write(_get_struct_3I().pack(_x.header.seq, _x.header.stamp.secs, _x.header.stamp.nsecs))
      _x = self.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self.text
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self.language
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_hq3hf2h().pack(_x.primitive, _x.utteranceIdentifier, _x.emotion, _x.paralinguistic, _x.pitch, _x.prosody_rate, _x.volume, _x.priority))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize_numpy(self, str, numpy):
    """
    unpack serialized message in str into this message instance using numpy for array types
    :param str: byte array of serialized message, ``str``
    :param numpy: numpy python module
    """
    codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      if self.header is None:
        self.header = std_msgs.msg.Header()
      end = 0
      _x = self
      start = end
      end += 12
      (_x.header.seq, _x.header.stamp.secs, _x.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.header.frame_id = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.text = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.text = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.language = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.language = str[start:end]
      _x = self
      start = end
      end += 24
      (_x.primitive, _x.utteranceIdentifier, _x.emotion, _x.paralinguistic, _x.pitch, _x.prosody_rate, _x.volume, _x.priority,) = _get_struct_hq3hf2h().unpack(str[start:end])
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill

_struct_I = genpy.struct_I
def _get_struct_I():
    global _struct_I
    return _struct_I
_struct_3I = None
def _get_struct_3I():
    global _struct_3I
    if _struct_3I is None:
        _struct_3I = struct.Struct("<3I")
    return _struct_3I
_struct_hq3hf2h = None
def _get_struct_hq3hf2h():
    global _struct_hq3hf2h
    if _struct_hq3hf2h is None:
        _struct_hq3hf2h = struct.Struct("<hq3hf2h")
    return _struct_hq3hf2h
